{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sfbllgrn/DD2412_Class_Contrastive_Explanations/blob/main/experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyJVkIHJo4fY"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/sfbllgrn/DD2412_Class_Contrastive_Explanations.git\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_folder = '/content/DD2412_Class_Contrastive_Explanations'\n",
        "destination_folder = '/content'\n",
        "\n",
        "# List the files and subdirectories in the source folder\n",
        "contents = os.listdir(source_folder)\n",
        "\n",
        "# Move each item from the source folder to the destination folder\n",
        "for item in contents:\n",
        "    source_path = os.path.join(source_folder, item)\n",
        "    destination_path = os.path.join(destination_folder, item)\n",
        "    shutil.move(source_path, destination_path)\n",
        "\n",
        "# Remove the now-empty source folder\n",
        "os.rmdir(source_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_c_lwZYNjSAo"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from torchvision.models import densenet161, DenseNet161_Weights    \n",
        "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
        "from torchvision.models import alexnet, AlexNet_Weights\n",
        "from torchvision.models import googlenet, GoogLeNet_Weights\n",
        "from torchvision.models import mnasnet0_5, MNASNet0_5_Weights # Här gissar jag att dom använder 0.5, står inte någonstans\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
        "from torchvision.models import efficientnet_b1, EfficientNet_B1_Weights\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd.functional import jacobian as J\n",
        "from torchvision.datasets import ImageFolder, ImageNet\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bo6tlZJkYMbA"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "\n",
        "data_folder = \"/Users/sofia/Documents/Skola/KTH/Master/Deep Learning, Advanced Course DD2412/Class Contrastive Explanations/val\"\n",
        "data_obj = ImageFolder(root=data_folder, transform=transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()])\n",
        "    )\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "val_dataloader = DataLoader(data_obj, batch_size=BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Init Pretrained models\n",
        "\n",
        "densenet = densenet161(weights=DenseNet161_Weights.IMAGENET1K_V1)\n",
        "mobilenet_small = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
        "alexnet = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
        "googlenet = googlenet(weights=GoogLeNet_Weights.IMAGENET1K_V1)\n",
        "mnasnet = mnasnet0_5(weights=MNASNet0_5_Weights.IMAGENET1K_V1)\n",
        "resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "mobilenet_large = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1)  # Denna har även IMAGENET1K_v2\n",
        "efficientnet = efficientnet_b1(weights=EfficientNet_B1_Weights.IMAGENET1K_V1) # Denna har även IMAGENET1K_v2\n",
        "pretrained_models = {\"densenet\":densenet, \"mobilenet_small\":mobilenet_small, \n",
        "                    \"alexnet\":alexnet, \"googlenet\":googlenet, \n",
        "                    \"mnasnet\":mnasnet, \"resnet\":resnet, \n",
        "                    \"mobilenet_large\":mobilenet_large, \n",
        "                    \"efficientnet\":efficientnet}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rIKc699zb1uz"
      },
      "outputs": [],
      "source": [
        "# Perform gradient sign pertubations\n",
        "\n",
        "\n",
        "def attribution_explanation(net, x):\n",
        "  value_logits = J(lambda x:net.model(x), x)\n",
        "  value_probs = J(lambda x:net.model(x).softmax(), x)\n",
        "  return value_logits, value_probs\n",
        "\n",
        "\n",
        "def gradient_sign_pertube(data, net, n):\n",
        "  epsilon = 1e-3\n",
        "  x = data\n",
        "  alpha = epsilon/n\n",
        "  outputs = net(x)\n",
        "  _, predictions = torch.max(outputs, 1)\n",
        "  for i in range(n):\n",
        "    # Att tänka ut: vilket x ska vi ha, xn eller original?\n",
        "    x = x + alpha*np.sign(attribution_explanation(net, data)[predictions])  # blir det rätt index här?\n",
        "    x = np.clip(x, np.min(x-epsilon, 0), np.max(x+epsilon, 1))\n",
        "  return x\n",
        "\n",
        "\n",
        "class PerturbationTransform:\n",
        "    def __init__(self, network, n):\n",
        "        self.network = network\n",
        "        self.n = n\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return gradient_sign_pertube(x, self.network, self.n)\n",
        "\n",
        "\n",
        "def get_perturbed_dataloader(net):\n",
        "  perturbed_dict = {}\n",
        "  for n in [2]:#[1,2,10]:\n",
        "    perturbed_dataset = ImageFolder(root=data_folder, transform=transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    PerturbationTransform(net, 1),  # Apply your Pertube function with the network\n",
        "    ]))\n",
        "    perturbed_dict[n] = DataLoader(perturbed_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "  return perturbed_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pretrained_models' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/9_/tjgwhcvn6nq39lnwk8yyqhwc0000gn/T/ipykernel_66161/233324813.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate on Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpretrained_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Set model to eval mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pretrained_models' is not defined"
          ]
        }
      ],
      "source": [
        "# Evaluate on Data\n",
        "\n",
        "for name, model in pretrained_models.items():\n",
        "    # Set model to eval mode\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        subset_size = 15\n",
        "        # Loop through a subset of the validation data\n",
        "        for batch_idx, (inputs, labels) in enumerate(val_dataloader):\n",
        "            if batch_idx < subset_size:\n",
        "                outputs = model(inputs)\n",
        "                # Calculate any metrics you need here\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "            else:\n",
        "                break \n",
        "        \n",
        "        accuracy = correct / total\n",
        "        print('Validation Accuracy for {} with original data: {}\\%'.format(name, accuracy*100))\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, model in pretrained_models.items():\n",
        "    # Set model to eval mode\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0  \n",
        "    \n",
        "    perturbed_dict = get_perturbed_dataloader(model)\n",
        "    with torch.no_grad():\n",
        "        correct_pert = 0\n",
        "        total_pert = 0\n",
        "        for n_iters, perturbed_dataloader in perturbed_dict.items():\n",
        "            for batch_idx, (inputs, labels) in enumerate(perturbed_dataloader):\n",
        "                if batch_idx < subset_size:\n",
        "                    outputs = model(inputs)\n",
        "                    # Calculate any metrics you need here\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    total_pert += labels.size(0)\n",
        "                    correct_pert += (predicted == labels).sum().item()\n",
        "                else:\n",
        "                    break \n",
        "        \n",
        "            accuracy_pert = correct_pert / total_pert\n",
        "            print('Validation Accuracy for {} with pertubed data, {} iterations: {}\\%'.format(name, n, accuracy_pert*100))\n",
        "            "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "interpreter": {
      "hash": "b2f5f294937e1f47dd6e010afb2ca0c96836afcb29d9a31a278c78890f03e991"
    },
    "kernelspec": {
      "display_name": "Python 3.7.16 64-bit ('venv': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}