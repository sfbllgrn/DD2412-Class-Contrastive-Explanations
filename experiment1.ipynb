{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sfbllgrn/DD2412_Class_Contrastive_Explanations/blob/main/experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyJVkIHJo4fY"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/sfbllgrn/DD2412_Class_Contrastive_Explanations.git\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_folder = '/content/DD2412_Class_Contrastive_Explanations'\n",
        "destination_folder = '/content'\n",
        "\n",
        "# List the files and subdirectories in the source folder\n",
        "contents = os.listdir(source_folder)\n",
        "\n",
        "# Move each item from the source folder to the destination folder\n",
        "for item in contents:\n",
        "    source_path = os.path.join(source_folder, item)\n",
        "    destination_path = os.path.join(destination_folder, item)\n",
        "    shutil.move(source_path, destination_path)\n",
        "\n",
        "# Remove the now-empty source folder\n",
        "os.rmdir(source_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c_lwZYNjSAo"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from torchvision.models import densenet161, DenseNet161_Weights    \n",
        "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
        "from torchvision.models import alexnet, AlexNet_Weights\n",
        "from torchvision.models import googlenet, GoogLeNet_Weights\n",
        "from torchvision.models import mnasnet0_5, MNASNet0_5_Weights # Här gissar jag att dom använder 0.5, står inte någonstans\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
        "from torchvision.models import efficientnet_b1, EfficientNet_B1_Weights\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd.functional import jacobian as J\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import sys\n",
        "from torchvision import transforms\n",
        "from copy import deepcopy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo6tlZJkYMbA"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "\n",
        "data_folder = \"/Users/sofia/Documents/Skola/KTH/Master/Deep Learning, Advanced Course DD2412/Class Contrastive Explanations/DD2412_Class_Contrastive_Explanations/Data_small\"\n",
        "data_obj = ImageFolder(root=data_folder, transform=DenseNet161_Weights.DEFAULT.transforms())\n",
        "\n",
        "BATCH_SIZE = 2\n",
        "val_dataloader = DataLoader(data_obj, batch_size=BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Init Pretrained models\n",
        "\n",
        "# densenet = densenet161(weights=DenseNet161_Weights.IMAGENET1K_V1)\n",
        "# mobilenet_small = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
        "alex = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
        "# google = googlenet(weights=GoogLeNet_Weights.IMAGENET1K_V1)\n",
        "# mnasnet = mnasnet0_5(weights=MNASNet0_5_Weights.IMAGENET1K_V1)\n",
        "resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "# mobilenet_large = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1)  # Denna har även IMAGENET1K_v2\n",
        "# efficientnet = efficientnet_b1(weights=EfficientNet_B1_Weights.IMAGENET1K_V1) # Denna har även IMAGENET1K_v2\n",
        "# pretrained_models = {\n",
        "#                     \"alexnet\":alex, \"googlenet\":google, \n",
        "#                     \"mnasnet\":mnasnet, \"resnet\":resnet, \n",
        "#                     \"mobilenet_large\":mobilenet_large, \n",
        "#                     \"efficientnet\":efficientnet,\n",
        "#                     \"densenet\":densenet, \"mobilenet_small\":mobilenet_small, }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIKc699zb1uz"
      },
      "outputs": [],
      "source": [
        "# Perform gradient sign pertubations\n",
        "\n",
        "def attribution_explanation(net, x, pred_indx):\n",
        "  value_logits = J(lambda x:net(x)[np.arange(BATCH_SIZE), pred_indx],x)\n",
        "  value_logits = torch.diagonal(value_logits)\n",
        "  value_logits = value_logits.permute(3, 0, 1, 2)\n",
        "  value_probs = J(lambda x:torch.nn.functional.softmax(net(x), dim=1)[np.arange(BATCH_SIZE),pred_indx], x)\n",
        "  value_probs = torch.diagonal(value_probs)\n",
        "  value_probs = value_probs.permute(3,0,1,2)\n",
        "  return value_logits, value_probs\n",
        "\n",
        "\n",
        "def gradient_sign_pertube(inputs, labels, net, n):\n",
        "  epsilon = 1e-3\n",
        "  x_logits = deepcopy(inputs)\n",
        "  x_probs = deepcopy(inputs)\n",
        "  alpha = epsilon/n\n",
        "  #outputs = net(inputs)\n",
        "  #_, predictions = torch.max(outputs, 1)\n",
        "\n",
        "  for i in range(n):\n",
        "    # Att tänka ut: ska det vara x eller data nedan\n",
        "    logits, probs = attribution_explanation(net, inputs, labels)\n",
        "    x_logits = x_logits + alpha*np.sign(logits)  # blir det rätt index här?\n",
        "    x_logits = np.clip(x_logits, np.minimum(x_logits-epsilon, 0), np.maximum(x_logits+epsilon, 1))\n",
        "    \n",
        "    x_probs = x_probs + alpha*np.sign(probs)  # blir det rätt index här?\n",
        "    x_probs = np.clip(x_probs, np.minimum(x_probs-epsilon, 0), np.maximum(x_probs+epsilon, 1))\n",
        "\n",
        "  return x_logits #, x_probs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Debug\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "name = \"alexnet\"\n",
        "model = alex\n",
        "# Set model to eval mode\n",
        "model.eval()\n",
        "\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "subset_size = 10\n",
        "correct = {\"probs\":0, \"logits\":0, \"unperturbed\":0}\n",
        "total = {\"probs\":0, \"logits\":0, \"unperturbed\":0}\n",
        "changes = {\"yt\":[], \"pt\":[]}\n",
        "\n",
        "n=1\n",
        "with torch.no_grad():\n",
        "    correct_pert = {\"probs\":0, \"logits\":0, \"unperturbed\":0}\n",
        "    total_pert = 0\n",
        "    for batch_idx, (inputs, labels) in enumerate(val_dataloader):\n",
        "        perturbed_x_logits = gradient_sign_pertube(inputs, labels, model, n)\n",
        "        if batch_idx < subset_size:\n",
        "            y_pert = model(perturbed_x_logits)\n",
        "            y = model(inputs)\n",
        "\n",
        "            yt_pert = deepcopy(y_pert[np.arange(BATCH_SIZE), labels])\n",
        "            yt = deepcopy(y[np.arange(BATCH_SIZE), labels])\n",
        "\n",
        "            changes['yt'].append(yt_pert-yt)\n",
        "\n",
        "            pt_pert = torch.nn.functional.softmax(y_pert, dim=1)[np.arange(BATCH_SIZE), labels]\n",
        "            pt = torch.nn.functional.softmax(y, dim=1)[np.arange(BATCH_SIZE), labels]\n",
        "            changes['pt'].append(pt_pert-pt)\n",
        "            \n",
        "            \n",
        "            #_, predicted_probs = torch.max(outputs_probs, 1)\n",
        "            _, predictions_pert = torch.max(y_pert, 1)\n",
        "            _, predictions_unperturbed = torch.max(y, 1)\n",
        "            total_pert += labels.size(0)\n",
        "            correct_pert[\"logits\"] += (predictions_pert == labels).sum().item()\n",
        "            #correct_pert[\"probs\"] += (predicted_probs == labels).sum().item()\n",
        "            correct_pert[\"unperturbed\"] += (predictions_unperturbed == labels).sum().item()\n",
        "\n",
        "        else:\n",
        "            break \n",
        "\n",
        "    accuracy_logits = correct_pert['logits']/ total_pert\n",
        "    #accuracy_probs = correct_pert['probs']/ total_pert\n",
        "    accuracy_unperturbed = correct_pert['unperturbed']/ total_pert\n",
        "\n",
        "    print(\"Average changes in yt: {} and pt: {}\".format(torch.mean(torch.stack(changes['yt'])), torch.mean(torch.stack(changes['pt']))))\n",
        "    print('Validation Accuracy for {} with pertubed data on logits, {} iterations: {}\\%'.format(name, n, accuracy_logits*100))\n",
        "    #print('Validation Accuracy for {} with pertubed data on probs, {} iterations: {}\\%'.format(name, n, accuracy_probs*100))\n",
        "    print('Validation Accuracy for {} with pertubed data on unperturbed data, {} iterations: {}\\%'.format(name, n, accuracy_unperturbed*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "interpreter": {
      "hash": "b2f5f294937e1f47dd6e010afb2ca0c96836afcb29d9a31a278c78890f03e991"
    },
    "kernelspec": {
      "display_name": "Python 3.7.16 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}