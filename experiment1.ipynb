{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sfbllgrn/DD2412_Class_Contrastive_Explanations/blob/main/experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyJVkIHJo4fY"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/sfbllgrn/DD2412_Class_Contrastive_Explanations.git\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_folder = '/content/DD2412_Class_Contrastive_Explanations'\n",
        "destination_folder = '/content'\n",
        "\n",
        "# List the files and subdirectories in the source folder\n",
        "contents = os.listdir(source_folder)\n",
        "\n",
        "# Move each item from the source folder to the destination folder\n",
        "for item in contents:\n",
        "    source_path = os.path.join(source_folder, item)\n",
        "    destination_path = os.path.join(destination_folder, item)\n",
        "    shutil.move(source_path, destination_path)\n",
        "\n",
        "# Remove the now-empty source folder\n",
        "os.rmdir(source_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google drive that contains all data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xvJHkbHtP-X4",
        "outputId": "88e39d02-16ac-46ff-9bf8-ab36f79c6c12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_c_lwZYNjSAo"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from torchvision.models import densenet161, DenseNet161_Weights\n",
        "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
        "from torchvision.models import alexnet, AlexNet_Weights\n",
        "from torchvision.models import googlenet, GoogLeNet_Weights\n",
        "from torchvision.models import mnasnet0_5, MNASNet0_5_Weights # Här gissar jag att dom använder 0.5, står inte någonstans\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
        "from torchvision.models import efficientnet_b1, EfficientNet_B1_Weights\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd.functional import jacobian as J\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import sys\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "from torch.nn.functional import one_hot\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "Dcrp-A_iovI6",
        "outputId": "cff1c210-0661-40e2-d762-29ba377b2a75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Bo6tlZJkYMbA"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "\n",
        "# when data is stored locally\n",
        "#data_folder = \"/Users/sofia/Documents/Skola/KTH/Master/Deep Learning, Advanced Course DD2412/Class Contrastive Explanations/DD2412_Class_Contrastive_Explanations/Data_small\"\n",
        "\n",
        "# for data stored on google drive\n",
        "data_folder = \"/content/drive/MyDrive/Colab Notebooks/Deep learning advanced/ImageNet_Data/val\"\n",
        "data_obj = ImageFolder(root=data_folder, transform=DenseNet161_Weights.DEFAULT.transforms())\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "val_dataloader = DataLoader(data_obj, batch_size=BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xp-QZ7E5P4jp"
      },
      "outputs": [],
      "source": [
        "# Init Pretrained models\n",
        "\n",
        "# debug:\n",
        "alex = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
        "pretrained_models = {\"alexnet\":alex}\n",
        "\n",
        "#densenet = densenet161(weights=DenseNet161_Weights.IMAGENET1K_V1)\n",
        "#mobilenet_small = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
        "#alex = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
        "#google = googlenet(weights=GoogLeNet_Weights.IMAGENET1K_V1)\n",
        "#mnasnet = mnasnet0_5(weights=MNASNet0_5_Weights.IMAGENET1K_V1)\n",
        "#resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "#mobilenet_large = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1)  # Denna har även IMAGENET1K_v2\n",
        "#efficientnet = efficientnet_b1(weights=EfficientNet_B1_Weights.IMAGENET1K_V1) # Denna har även IMAGENET1K_v2\n",
        "#pretrained_models = {\n",
        " #                    \"alexnet\":alex, \"googlenet\":google,\n",
        " #                    \"mnasnet\":mnasnet, \"resnet\":resnet,\n",
        " #                    \"mobilenet_large\":mobilenet_large,\n",
        " #                    \"efficientnet\":efficientnet,\n",
        " #                    \"densenet\":densenet, \"mobilenet_small\":mobilenet_small}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rIKc699zb1uz"
      },
      "outputs": [],
      "source": [
        "# Perform gradient sign pertubations\n",
        "\n",
        "def calculate_weighted_contrast(x, t, net):\n",
        "  \"\"\"Calculated weighted attribute explanation.\n",
        "  Inputs:\n",
        "    - X: one tensor input data (image), with shape (1,3,224,224)\n",
        "    - t: one-dimensional tensor containing target class for the input img\n",
        "    - net: network model\"\"\"\n",
        "\n",
        "  logits = net(x)\n",
        "  num_classes = logits.shape[1]\n",
        "  phi_t = calculate_gradient(x, t, net)\n",
        "\n",
        "  weighted_explanation = phi_t\n",
        "  alpha_denominator = torch.sum(torch.exp(logits), dim=1)-torch.exp(logits[0,t])\n",
        "  for s in range(num_classes):\n",
        "    if s!=t:\n",
        "      s = torch.tensor(s).to(device)\n",
        "      alpha_s = torch.exp(logits[0,s])/alpha_denominator\n",
        "      phi_s = calculate_gradient(x, s, net)\n",
        "      weighted_explanation -= alpha_s*phi_s\n",
        "  return weighted_explanation\n",
        "\n",
        "\n",
        "def calculate_max_contrast(x, t, net):\n",
        "  logits = net(x)\n",
        "  num_classes = logits.shape[1]\n",
        "  logits[t] = -1000000000  # because we want to take argmax on logits except t. I assume that there will always be a logit larger than this value\n",
        "  s_star = torch.argmax(logits)\n",
        "  phi_s_star = calculate_gradient(x, s_star, net)\n",
        "  phi_t = calculate_gradient(x, t, net)\n",
        "  return phi_t - phi_s_star\n",
        "\n",
        "\n",
        "def calculate_mean_contrast(x, t, net):\n",
        "    logits = net(x)\n",
        "    num_classes = logits.shape[1]\n",
        "    phi_t = calculate_gradient(x,t,net)\n",
        "    mean_contrast = phi_t\n",
        "    for s in range(num_classes):\n",
        "      if s!=t:\n",
        "        s = torch.tensor(s).to(device)\n",
        "        phi_s = calculate_gradient(x,s,net)\n",
        "        mean_contrast -= phi_s/(num_classes-1)\n",
        "    return mean_contrast\n",
        "\n",
        "\n",
        "def get_attribute_explanation(x, t, net, contrast_type):\n",
        "  if contrast_type==\"original\":\n",
        "    return calculate_gradient(x, t, net)\n",
        "  elif contrast_type==\"weighted\":\n",
        "    return calculate_weighted_contrast(x, t, net)\n",
        "  elif contrast_type==\"mean\":\n",
        "    return calculate_mean_contrast(x, t, net)\n",
        "  elif contrast_type==\"max\":\n",
        "    return calculate_max_contrast(x, t, net)\n",
        "\n",
        "\n",
        "def calculate_gradient(x, t, net, probs=False):\n",
        "  logits = net(x)\n",
        "  pred_probab = nn.Softmax(dim=1)(logits)\n",
        "  yt_oh = one_hot(t, num_classes=logits.shape[1])\n",
        "  external_grad = torch.reshape(yt_oh, logits.shape)\n",
        "  x.retain_grad()   # Enables this Tensor to have their grad populated during backward() even if it is not a leaf node ?\n",
        "  if probs:\n",
        "    pred_probab.backward(gradient=external_grad)\n",
        "    return x.grad\n",
        "\n",
        "  logits.backward(gradient=external_grad)\n",
        "\n",
        "  return x.grad\n",
        "\n",
        "def calculate_gradient_old(net, x, pred_indx):\n",
        "  value_logits = J(lambda x:net(x)[np.arange(BATCH_SIZE), pred_indx],x)\n",
        "  value_logits = torch.diagonal(value_logits)\n",
        "  value_logits = value_logits.permute(3,0,1,2)\n",
        "  #value_probs = J(lambda x:torch.nn.functional.softmax(net(x), dim=1)[np.arange(BATCH_SIZE),pred_indx], x)\n",
        "  #value_probs = torch.diagonal(value_probs)\n",
        "  #value_probs = value_probs.permute(3,0,1,2)\n",
        "  return value_logits\n",
        "\n",
        "\n",
        "def gradient_sign_pertube(x, t, net, n, contrast_type=\"original\"):\n",
        "  epsilon = 1e-3\n",
        "  xn = x.clone()\n",
        "  alpha = epsilon/n\n",
        "  for i in range(n):\n",
        "    # Att tänka ut: ska det vara x eller data nedan\n",
        "    logits = get_attribute_explanation(x, t, net, contrast_type)\n",
        "    xn = xn + alpha*torch.sign(logits)  # blir det rätt index här?\n",
        "    xn = torch.clamp(xn, min=torch.minimum(x-epsilon, torch.tensor(0)), max=torch.maximum(x+epsilon, torch.tensor(1)))\n",
        "\n",
        "  return xn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUE29iY0P4jx"
      },
      "source": [
        "## Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "C7Yo03J7P4j3",
        "outputId": "9944ec11-a810-4487-f32a-bf793697b276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "tensor([0])\n",
            "0.5\n",
            "tensor([0])\n",
            "1.0\n",
            "Average changes in yt: -0.24493789672851562 and pt: 1.2609176337718964e-05\n",
            "Change in accuracy for model alexnet using 1 iterations: 0\\%\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "n=1\n",
        "\n",
        "model_names = [\"alexnet\"]\n",
        "\n",
        "for name in model_names:\n",
        "  model = pretrained_models[name].to(device)\n",
        "  model.eval()\n",
        "\n",
        "  #eval_size = len(data_obj)  # eval on all data\n",
        "  eval_size = 2             # eval on small subset, for debug\n",
        "\n",
        "  perturbation_types = [\"weighted\"]#, \"mean\", \"original\", \"max\"]\n",
        "  accuracy_dict = {p_type:0 for p_type in perturbation_types}\n",
        "  accuracy_dict[\"unperturbed\"] = 0\n",
        "  perturbation_changes = {key:{\"yt\":[], \"pt\":[]} for key in perturbation_types}\n",
        "\n",
        "  for batch_idx, (input, target) in enumerate(val_dataloader):\n",
        "      #if batch_idx%eval_size/10 == 0:\n",
        "      print(batch_idx/eval_size)\n",
        "\n",
        "      if batch_idx < eval_size:\n",
        "\n",
        "          input.requires_grad_(True)\n",
        "          input = input.to(device)\n",
        "          target = target.to(device)\n",
        "\n",
        "          y = model(input)\n",
        "          yt = y[np.arange(BATCH_SIZE), target]\n",
        "          pt = torch.nn.functional.softmax(y, dim=1)[np.arange(BATCH_SIZE), target]\n",
        "          _, prediction_unperturbed = torch.max(y, 1)\n",
        "          if prediction_unperturbed == target:\n",
        "            accuracy_dict[\"unperturbed\"] += 1/eval_size\n",
        "\n",
        "          for perturbation_type in perturbation_types:\n",
        "            # perturbed x with respect to logits\n",
        "            print(perturbation_type)\n",
        "            x_perturbed = gradient_sign_pertube(input, target, model, n, perturbation_type)\n",
        "            y_perturbed = model(x_perturbed)\n",
        "            yt_perturbed = y_perturbed[np.arange(BATCH_SIZE), target]\n",
        "\n",
        "            # Save the change in yt before and after perturbation\n",
        "            perturbation_changes[perturbation_type]['yt'].append(yt_perturbed-yt)\n",
        "\n",
        "            # Calculate and save change in pt before and after perturbation\n",
        "            pt_perturbed = torch.nn.functional.softmax(y_perturbed, dim=1)[np.arange(BATCH_SIZE), target]\n",
        "            perturbation_changes[perturbation_type]['pt'].append(pt_perturbed-pt)\n",
        "\n",
        "            # Store result of perturbed prediction\n",
        "            _, prediction_perturbed = torch.max(y_perturbed, 1)\n",
        "            if prediction_perturbed == target:\n",
        "              accuracy_dict[perturbation_type] += 1/eval_size\n",
        "      else:\n",
        "          break\n",
        "\n",
        "\n",
        "  for perturbation_type in perturbation_types:\n",
        "    avg_pt_change = torch.mean(torch.stack(perturbation_changes[perturbation_type]['pt']))\n",
        "    avg_yt_change = torch.mean(torch.stack(perturbation_changes[perturbation_type]['yt']))\n",
        "    accuracy_change = accuracy_dict[perturbation_type]-accuracy_dict['unperturbed']\n",
        "    print(\"Average changes in yt: {} and pt: {}\".format(avg_yt_change, avg_pt_change))\n",
        "    print('Change in accuracy for model {} using {} iterations: {}\\%'.format(name, n, accuracy_change))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# rearrange change_dictionary to desired format:\n",
        "measurements = {\"yt\":tuple([perturbation_changes[p_type]['yt'] for p_type in perturbation_types]),\n",
        "                \"pt\":tuple([perturbation_changes[p_type]['pt'] for p_type in perturbation_types]),\n",
        "                \"acc\":tuple([accuracy_change[p_type] for p_type in perturbation_types])\n",
        "                }\n",
        "\n",
        "\n",
        "print(measurements)\n",
        "fig, axs = plt.subplots(len(model_names), layout=\"constrained\")\n",
        "\n",
        "model_name = \"alexnet\"\n",
        "#\n",
        "#for i,model_name in enumerate(model_names):\n",
        "#  axs[i].set_title(model_name)\n",
        "axs.set_title(model_name)\n",
        "width = 0.25\n",
        "multiplier = 0\n",
        "x = np.arange(len(perturbation_types))\n",
        "\n",
        "for attribute, measurement in measurements.items():\n",
        "    print(measurement)\n",
        "    offset = width * multiplier\n",
        "    rects = axs.bar(x + offset, measurement, width, label=attribute)\n",
        "    axs.bar_label(rects, padding=3)\n",
        "    multiplier += 1\n",
        "\n",
        "\n",
        "x_tickes = (p_type for p_type in perturbation_types)\n",
        "axs.set_xticks(x + width, x_tickes)\n",
        "axs.legend(loc='upper left', ncols=3)\n",
        "axs.set_ylim(0, 250)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yL6AUjAhc-8O",
        "outputId": "313e6c1b-78ac-494b-a16d-e16413cde105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-2e7117d4572d>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m measurements = {\"yt\":tuple([perturbation_changes[p_type]['yt'] for p_type in perturbation_types]),\n\u001b[1;32m      8\u001b[0m                 \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperturbation_changes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperturbation_types\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \"acc\": tuple([accuracy_change[p_type] for p_type in perturbation_types])}\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-2e7117d4572d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m measurements = {\"yt\":tuple([perturbation_changes[p_type]['yt'] for p_type in perturbation_types]),\n\u001b[1;32m      8\u001b[0m                 \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperturbation_changes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperturbation_types\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \"acc\": tuple([accuracy_change[p_type] for p_type in perturbation_types])}\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "b2f5f294937e1f47dd6e010afb2ca0c96836afcb29d9a31a278c78890f03e991"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}